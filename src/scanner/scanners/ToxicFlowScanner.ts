// ToxicFlowScanner.ts
import * as fs from 'fs';
import * as path from 'path';
import { AbstractScanner } from '../BaseScanner';
import { Vulnerability } from '../../types/Vulnerability';
import { MCPScanner } from '../McpScanner';

export class ToxicFlowScanner extends AbstractScanner {
  async scan(projectPath: string): Promise<Vulnerability[]> {
    console.log('ðŸŒŠ Scanning for toxic agent flows...');

    const vulnerabilities: Vulnerability[] = [];
    const files = MCPScanner.getAllFiles(projectPath, ['.ts', '.js', '.py']);

    for (const file of files) {
      const content = fs.readFileSync(file, 'utf8');
      const lines = content.split('\n');

      lines.forEach((line, index) => {
        if (this.containsUntrustedDataProcessing(line)) {
          vulnerabilities.push({
            id: 'UNTRUSTED_DATA_PROCESSING',
            severity: 'medium',
            category: 'toxic-flow',
            message: 'External data processed without sanitization',
            file: path.relative(projectPath, file),
            line: index + 1,
            evidence: line.trim(),
            source: 'Invariant Labs research',
          });
        }

        if (this.containsAutomaticPublishing(line)) {
          vulnerabilities.push({
            id: 'AUTOMATIC_CONTENT_PUBLISHING',
            severity: 'high',
            category: 'toxic-flow',
            message: 'Automatic content publishing - data exfiltration risk',
            file: path.relative(projectPath, file),
            line: index + 1,
            evidence: line.trim(),
            source: 'Invariant Labs research',
          });
        }
      });

      this.analyzeGenericToxicChains(
        content,
        file,
        projectPath,
        vulnerabilities,
      );
    }

    return vulnerabilities;
  }

  private containsUntrustedDataProcessing(line: string): boolean {
    const untrustedDataSources = [
      /\.data\.|response\.|\.json\(\)|\.text\(\)/,
      /readFile|read.*content|fetch.*file/i,
      /input\.|params\.|query\.|body\./,
      /fetch\(|axios\.|request\(|http\./,
      /message\.content|content\.body|data\.content/i,
      /external|remote|api|endpoint/i,
    ];

    const hasUntrustedSource = untrustedDataSources.some((pattern) =>
      pattern.test(line),
    );
    if (!hasUntrustedSource) return false;

    const sanitizationPresent = [
      /sanitize|escape|validate|filter|clean/i,
      /allowlist|whitelist|strip|remove/i,
      /encode|decode|parse.*safe|safe.*parse/i,
    ];

    return !sanitizationPresent.some((sanitization) => sanitization.test(line));
  }

  private containsAutomaticPublishing(line: string): boolean {
    const publishingPatterns = [
      /create(?!.*test)|auto.*create|generate.*content/i,
      /publish|send|post|upload|write.*file/i,
      /broadcast|share|distribute|forward/i,
      /notify|alert|message|email/i,
      /insert|save|store.*public/i,
    ];

    const hasPublishing = publishingPatterns.some((pattern) =>
      pattern.test(line),
    );
    if (!hasPublishing) return false;

    const dynamicContentIndicators = [
      /\$\{|template|interpolate|\+.*\+/,
      /\.data|response\.|content\.|input\./,
      /process\.|param|arg|variable/,
    ];

    return dynamicContentIndicators.some((indicator) => indicator.test(line));
  }

  private analyzeGenericToxicChains(
    content: string,
    file: string,
    projectPath: string,
    vulnerabilities: Vulnerability[],
  ) {
    const lines = content.split('\n');

    let hasExternalInput = false;
    let hasPrivilegedAccess = false;
    let hasPublicOutput = false;

    lines.forEach((line) => {
      if (/fetch|api|external|remote|input|request/i.test(line)) {
        hasExternalInput = true;
      }

      if (/private|confidential|secret|internal|admin|privileged/i.test(line)) {
        hasPrivilegedAccess = true;
      }

      if (/public|create|publish|send|post|share|broadcast/i.test(line)) {
        hasPublicOutput = true;
      }
    });

    if (hasExternalInput && hasPrivilegedAccess && hasPublicOutput) {
      vulnerabilities.push({
        id: 'GENERIC_TOXIC_FLOW_CHAIN',
        severity: 'critical',
        category: 'toxic-flow',
        message:
          'Complete toxic flow: external input â†’ privileged access â†’ public output',
        file: path.relative(projectPath, file),
        evidence:
          'File contains external input processing, privileged data access, and public output mechanisms',
        source: 'Invariant Labs research',
      });
    }
  }
}
